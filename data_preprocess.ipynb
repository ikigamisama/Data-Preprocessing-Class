{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280cfcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pipeline_data_preprocessing import DataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3613285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Dataset ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.967142</td>\n",
       "      <td>70990.331549</td>\n",
       "      <td>40.710649</td>\n",
       "      <td>C</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33.617357</td>\n",
       "      <td>63869.505244</td>\n",
       "      <td>6.600984</td>\n",
       "      <td>C</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41.476885</td>\n",
       "      <td>50894.455549</td>\n",
       "      <td>34.882053</td>\n",
       "      <td>D</td>\n",
       "      <td>New York</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50.230299</td>\n",
       "      <td>40295.948334</td>\n",
       "      <td>11.099810</td>\n",
       "      <td>B</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>32.658466</td>\n",
       "      <td>60473.349704</td>\n",
       "      <td>80.823521</td>\n",
       "      <td>D</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>32.188997</td>\n",
       "      <td>66052.253575</td>\n",
       "      <td>34.264515</td>\n",
       "      <td>B</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>52.976865</td>\n",
       "      <td>49602.181111</td>\n",
       "      <td>86.465892</td>\n",
       "      <td>D</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>41.408429</td>\n",
       "      <td>36771.880232</td>\n",
       "      <td>15.492531</td>\n",
       "      <td>D</td>\n",
       "      <td>London</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>29.288210</td>\n",
       "      <td>47553.995541</td>\n",
       "      <td>8.273684</td>\n",
       "      <td>A</td>\n",
       "      <td>New York</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>40.725828</td>\n",
       "      <td>38826.460328</td>\n",
       "      <td>48.453800</td>\n",
       "      <td>D</td>\n",
       "      <td>New York</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id        age        income      score category      city  \\\n",
       "0              1  39.967142  70990.331549  40.710649        C     Paris   \n",
       "1              2  33.617357  63869.505244   6.600984        C     Tokyo   \n",
       "2              3  41.476885  50894.455549  34.882053        D  New York   \n",
       "3              4  50.230299  40295.948334  11.099810        B     Tokyo   \n",
       "4              5  32.658466  60473.349704  80.823521        D     Paris   \n",
       "..           ...        ...           ...        ...      ...       ...   \n",
       "995          996  32.188997  66052.253575  34.264515        B     Tokyo   \n",
       "996          997  52.976865  49602.181111  86.465892        D     Paris   \n",
       "997          998  41.408429  36771.880232  15.492531        D    London   \n",
       "998          999  29.288210  47553.995541   8.273684        A  New York   \n",
       "999         1000  40.725828  38826.460328  48.453800        D  New York   \n",
       "\n",
       "    date_joined  target  \n",
       "0    2020-01-01       0  \n",
       "1    2020-01-02       0  \n",
       "2    2020-01-03       0  \n",
       "3    2020-01-04       0  \n",
       "4    2020-01-05       1  \n",
       "..          ...     ...  \n",
       "995  2022-09-22       1  \n",
       "996  2022-09-23       1  \n",
       "997  2022-09-24       0  \n",
       "998  2022-09-25       1  \n",
       "999  2022-09-26       1  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample dataset\n",
    "n_samples = 1000\n",
    "sample_data = {\n",
    "    'customer_id': range(1, n_samples + 1),\n",
    "    'age': np.random.normal(35, 10, n_samples),\n",
    "    'income': np.random.normal(50000, 15000, n_samples),\n",
    "    'score': np.random.uniform(0, 100, n_samples),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], n_samples),\n",
    "    'city': np.random.choice(['New York', 'London', 'Tokyo', 'Sydney', 'Paris'], n_samples),\n",
    "    'date_joined': pd.date_range('2020-01-01', periods=n_samples, freq='D'),\n",
    "    'target': np.random.choice([0, 1], n_samples)\n",
    "}\n",
    "\n",
    "# Add some missing values and outliers\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "sample_df.loc[50:60, 'income'] = np.nan\n",
    "sample_df.loc[100:110, 'age'] = np.nan\n",
    "sample_df.loc[200:205, 'category'] = np.nan\n",
    "sample_df.loc[20:25, 'income'] = 200000  # outliers\n",
    "\n",
    "print(\"=== Sample Dataset ===\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e092b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 8)\n",
      "Missing values:\n",
      "customer_id     0\n",
      "age            11\n",
      "income         11\n",
      "score           0\n",
      "category        6\n",
      "city            0\n",
      "date_joined     0\n",
      "target          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.967142</td>\n",
       "      <td>70990.331549</td>\n",
       "      <td>40.710649</td>\n",
       "      <td>C</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33.617357</td>\n",
       "      <td>63869.505244</td>\n",
       "      <td>6.600984</td>\n",
       "      <td>C</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41.476885</td>\n",
       "      <td>50894.455549</td>\n",
       "      <td>34.882053</td>\n",
       "      <td>D</td>\n",
       "      <td>New York</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50.230299</td>\n",
       "      <td>40295.948334</td>\n",
       "      <td>11.099810</td>\n",
       "      <td>B</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>32.658466</td>\n",
       "      <td>60473.349704</td>\n",
       "      <td>80.823521</td>\n",
       "      <td>D</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id        age        income      score category      city  \\\n",
       "0            1  39.967142  70990.331549  40.710649        C     Paris   \n",
       "1            2  33.617357  63869.505244   6.600984        C     Tokyo   \n",
       "2            3  41.476885  50894.455549  34.882053        D  New York   \n",
       "3            4  50.230299  40295.948334  11.099810        B     Tokyo   \n",
       "4            5  32.658466  60473.349704  80.823521        D     Paris   \n",
       "\n",
       "  date_joined  target  \n",
       "0  2020-01-01       0  \n",
       "1  2020-01-02       0  \n",
       "2  2020-01-03       0  \n",
       "3  2020-01-04       0  \n",
       "4  2020-01-05       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"Missing values:\\n{sample_df.isnull().sum()}\")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a7aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXAMPLE 1: Quick preprocessing with target column\n",
      "==================================================\n",
      "[19:04:58] Data loaded from DataFrame\n",
      "[19:04:58] Dataset shape: (1000, 8)\n",
      "[19:04:58] Numeric features: 0\n",
      "[19:04:58] Categorical features: 2\n",
      "[19:04:58] Target column(s): ['target']\n",
      "[19:04:58] Missing values: 28\n",
      "[19:04:58] Starting quick preprocessing pipeline...\n",
      "[19:04:58] Removed ID columns: ['customer_id', 'age', 'income', 'score', 'date_joined']\n",
      "[19:04:58] Shape changed from (1000, 8) to (1000, 3)\n",
      "[19:04:58] Applied most_frequent imputation to categorical features\n",
      "[19:04:58] No numeric features found for outlier handling\n",
      "[19:04:58] Encoded categorical features using auto\n",
      "[19:04:58] No numeric features found for scaling\n",
      "[19:04:58] Quick preprocessing completed!\n",
      "\n",
      "Processed shape: (1000, 8)\n",
      "Final columns: ['target', 'category_B', 'category_C', 'category_D', 'city_New York', 'city_Paris', 'city_Sydney', 'city_Tokyo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample, errors='raise',\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Quick preprocessing with specific target\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXAMPLE 1: Quick preprocessing with target column\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "preprocessor1 = DataPreprocessor(sample_df.copy(), target_column='target')\n",
    "processed_data1 = preprocessor1.quick_preprocess()\n",
    "\n",
    "print(f\"\\nProcessed shape: {processed_data1.shape}\")\n",
    "print(f\"Final columns: {list(processed_data1.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb5676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXAMPLE 2: Step-by-step preprocessing\n",
      "==================================================\n",
      "[19:04:58] Data loaded from DataFrame\n",
      "[19:04:58] Dataset shape: (1000, 8)\n",
      "[19:04:58] Numeric features: 0\n",
      "[19:04:58] Categorical features: 2\n",
      "[19:04:58] Target column(s): ['target']\n",
      "[19:04:58] Missing values: 28\n",
      "[19:04:58] Removed ID columns: ['customer_id', 'age', 'income', 'score', 'date_joined']\n",
      "[19:04:58] Shape changed from (1000, 8) to (1000, 3)\n",
      "[19:04:58] Applied most_frequent imputation to categorical features\n",
      "[19:04:58] No numeric features found for outlier handling\n",
      "[19:04:58] Encoded categorical features using onehot\n",
      "[19:04:58] No numeric features found for scaling\n",
      "\n",
      "Processed shape: (1000, 8)\n",
      "Missing values after processing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample, errors='raise',\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Step-by-step preprocessing\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXAMPLE 2: Step-by-step preprocessing\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "preprocessor2 = DataPreprocessor(sample_df.copy(), target_column='target')\n",
    "processed_data2 = (preprocessor2\n",
    "                    .clean_data()\n",
    "                    .handle_missing_values('median')\n",
    "                    .handle_outliers('iqr')\n",
    "                    .encode_categorical('onehot')\n",
    "                    .scale_features('standard')\n",
    "                    .get_processed_data())\n",
    "\n",
    "print(f\"\\nProcessed shape: {processed_data2.shape}\")\n",
    "print(f\"Missing values after processing: {processed_data2.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcb53e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXAMPLE 3: Process all columns (no target exclusion)\n",
      "==================================================\n",
      "[19:04:58] Data loaded from DataFrame\n",
      "[19:04:58] Dataset shape: (1000, 8)\n",
      "[19:04:58] Numeric features: 0\n",
      "[19:04:58] Categorical features: 0\n",
      "[19:04:58] Target column(s): ['customer_id', 'age', 'income', 'score', 'category', 'city', 'date_joined', 'target']\n",
      "[19:04:58] Missing values: 28\n",
      "[19:04:58] Starting quick preprocessing pipeline...\n",
      "[19:04:58] No numeric features found for outlier handling\n",
      "[19:04:58] No categorical features found\n",
      "[19:04:58] No numeric features found for scaling\n",
      "[19:04:58] Quick preprocessing completed!\n",
      "\n",
      "Processed shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Process all columns\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXAMPLE 3: Process all columns (no target exclusion)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "preprocessor3 = DataPreprocessor(sample_df.copy(), target_column=\"all\")\n",
    "processed_data3 = preprocessor3.quick_preprocess()\n",
    "\n",
    "print(f\"\\nProcessed shape: {processed_data3.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f43cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXAMPLE 4: Custom preprocessing strategies\n",
      "==================================================\n",
      "[19:04:58] Data loaded from DataFrame\n",
      "[19:04:58] Dataset shape: (1000, 8)\n",
      "[19:04:58] Numeric features: 0\n",
      "[19:04:58] Categorical features: 2\n",
      "[19:04:58] Target column(s): ['target', 'score']\n",
      "[19:04:58] Missing values: 28\n",
      "[19:04:58] Removed ID columns: ['customer_id', 'age', 'income', 'date_joined']\n",
      "[19:04:58] Shape changed from (1000, 8) to (1000, 4)\n",
      "[19:04:58] Applied custom imputation strategies: {'age': 'median', 'income': 'mean', 'category': 'most_frequent'}\n",
      "[19:04:58] No numeric features found for outlier handling\n",
      "[19:04:58] Encoded categorical features using auto\n",
      "[19:04:58] No numeric features found for scaling\n",
      "\n",
      "Processed shape: (1000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pd.to_datetime(sample, errors='raise',\n",
      "f:\\aTO THE FUTURE\\python\\Data Engineering\\Tutorial\\Data Preprocessing\\pipeline_data_preprocessing.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample, errors='raise',\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Custom strategies\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXAMPLE 4: Custom preprocessing strategies\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "preprocessor4 = DataPreprocessor(sample_df.copy(), target_column=['target', 'score'])\n",
    "processed_data4 = (preprocessor4\n",
    "                    .clean_data(remove_id_columns=True)\n",
    "                    .handle_missing_values({'age': 'median', 'income': 'mean', 'category': 'most_frequent'})\n",
    "                    .handle_outliers('isolation_forest', contamination=0.05)\n",
    "                    .encode_categorical('auto', max_categories=5)\n",
    "                    .scale_features('robust')\n",
    "                    .remove_low_variance(threshold=0.01)\n",
    "                    .get_processed_data())\n",
    "\n",
    "print(f\"\\nProcessed shape: {processed_data4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a2b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PREPROCESSING SUMMARY\n",
      "==================================================\n",
      "Original shape: (1000, 8)\n",
      "Final shape: (1000, 9)\n",
      "Processing steps: 12\n",
      "Numeric features: 0\n",
      "Categorical features: 7\n",
      "\n",
      "Processing log (last 5 steps):\n",
      "  [19:04:58] Shape changed from (1000, 8) to (1000, 4)\n",
      "  [19:04:58] Applied custom imputation strategies: {'age': 'median', 'income': 'mean', 'category': 'most_frequent'}\n",
      "  [19:04:58] No numeric features found for outlier handling\n",
      "  [19:04:58] Encoded categorical features using auto\n",
      "  [19:04:58] No numeric features found for scaling\n"
     ]
    }
   ],
   "source": [
    "# Show summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "summary = preprocessor4.get_summary()\n",
    "print(f\"Original shape: {summary['original_shape']}\")\n",
    "print(f\"Final shape: {summary['final_shape']}\")\n",
    "print(f\"Processing steps: {summary['processing_steps']}\")\n",
    "print(f\"Numeric features: {summary['numeric_features']}\")\n",
    "print(f\"Categorical features: {summary['categorical_features']}\")\n",
    "\n",
    "print(f\"\\nProcessing log (last 5 steps):\")\n",
    "for step in summary['processing_log'][-5:]:\n",
    "    print(f\"  {step}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
